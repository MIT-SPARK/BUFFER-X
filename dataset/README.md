<div align="center">
    <h1>BUFFER-X (ICCV 2025, ğŸŒŸHighlightedğŸŒŸ)</h1>
    <p align="center">
      <a href="https://scholar.google.com/citations?user=esoiHnYAAAAJ&hl=en">Minkyun Seo*</a>,
      <a href="https://scholar.google.com/citations?user=S1A3nbIAAAAJ&hl=en">Hyungtae Lim*</a>,
      <a href="https://scholar.google.com/citations?user=s-haNkwAAAAJ&hl=en">Kanghee Lee</a>,
      <a href="https://scholar.google.com/citations?user=U4kKRdMAAAAJ&hl=it">Luca Carlone</a>,
      <a href="https://scholar.google.com/citations?user=_3q6KBIAAAAJ&hl=en">Jaesik Park</a>
      <br />
    </p>
    <a href="https://github.com/MIT-SPARK/BUFFER-X"><img src="https://img.shields.io/badge/Python-3670A0?logo=python&logoColor=ffdd54" /></a>
    <a href="https://github.com/MIT-SPARK/BUFFER-X"><img src="https://img.shields.io/badge/Linux-FCC624?logo=linux&logoColor=black" /></a>
    <a href="https://arxiv.org/abs/2503.07940"><img src="https://img.shields.io/badge/arXiv-b33737?logo=arXiv" /></a>
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/legalcode"><img src="https://img.shields.io/badge/license-CC4.0-blue.svg" /></a>
  <br />
  <br />
  <p align="center"><img src="https://github.com/user-attachments/assets/8cbc95e2-7dc8-46af-9691-b136eb36caad" alt="BUFFER-X" width="95%"/></p>
  <p><strong><em>Towards zero-shot and beyond! ğŸš€ <br>
  Official repository of BUFFER-X, a zero-shot point cloud registration method<br> across diverse scenes without retraining or tuning.</em></strong></p>
</div>

______________________________________________________________________

# Generalization Benchmark in BUFFER-X

This document provides an overview of the datasets used in our experiments. The datasets are categorized into indoor and outdoor datasets. Each entry includes brief instructions and expected folder structures for proper use.

You can click the links below to jump to each dataset section.

## ğŸš€ Quick Start

Except for the 'ScanNet++ iPhone' and 'ScanNet++ Faro' datasets, all other datasets can be downloaded in a single command. To download the datasets, run the following command:

```bash
./scripts/download_all_data.sh
```

This script will download all datasets and place them in the `datasets` directory. The expected folder structure is as follows:

```
â”œâ”€â”€ BUFFER-X/
â””â”€â”€ datasets/
    â”œâ”€â”€ ThreeDMatch/
    â”œâ”€â”€ tiers_indoor/
    â”œâ”€â”€ kitti/
    â”œâ”€â”€ WOD/
    â”œâ”€â”€ helipr_kaist05/
    â”œâ”€â”€ kimera-multi/
    â”œâ”€â”€ ETH/
    â””â”€â”€ newer-college/
```

For ScanNet++ iPhone and Faro datasets, please follow the instructions in their respective sections below.

## ğŸ› ï¸ How to Parse ScanNet++ Datasets

Due to dataset sharing policies (i.e., redistribution of modified files by third parties is not allowed), we are unable to provide the preprocessed ScanNet++ iPhone and FARO data. Please download the raw ScanNet++ dataset directly from the official source and run our preprocessing scripts.

Place the downloaded ScanNet++ dataset into the `datasets` directory. The expected folder structure is as follows:

```
â”œâ”€â”€ BUFFER-X/
â””â”€â”€ datasets/
    â””â”€â”€ scannetpp/
        â””â”€â”€ scannet-plusplus/
            â””â”€â”€ data/
                â”œâ”€â”€ 0a5c013435/
                â”‚   â”œâ”€â”€ iphone/
                â”‚   â””â”€â”€ scans/
                â””â”€â”€ ...
```

Setup your **own virtual environment** (e.g., `conda create -n scannetpp_process python=3.x` or setting your Nvidia Docker env.) and then install the required libraries.
Then run the following commands to set up the environment.

```bash
cd dataset/scannetpp
./env_setup.sh
```

Then run the preprocessing script to generate the required data structure:

```bash
./scannetpp_iphone_preprocess.sh
./scannetpp_faro_preprocess.sh
```

This process takes a very long time â€” approximately 6 to 10 hours depending on your hardware. Please ensure you have enough time and resources before starting.

______________________________________________________________________

## ğŸ“‚ Additional Explanations About Datasets

### ğŸ“Œ Indoor Datasets

- [1. 3DMatch](#1-3dmatch)
- [2. 3DLoMatch](#2-3dlomatch)
- [3. ScanNet++ iPhone](#3-scannet-iphone)
- [4. ScanNet++ Faro](#4-scannet-faro)
- [5. TIERS](#5-tiers)

### ğŸ“Œ Outdoor Datasets

- [6. KITTI](#6-kitti)
- [7. Waymo Open Dataset](#7-waymo-open-dataset)
- [8. KAIST](#8-kaist)
- [9. MIT](#9-mit)
- [10. ETH](#10-eth)
- [11. Oxford](#11-oxford)

## Indoor Datasets

### (1) 3DMatch

Following [Predator](https://github.com/prs-eth/OverlapPredator.git), we provide the processed 3DMatch training set (subsampled fragments with voxel size of 1.5cm and their ground truth transformation matrices).

The structure should be as follows:

```
datasets/
â””â”€â”€ ThreeDMatch/
    â”œâ”€â”€ train/
    â”‚   â”œâ”€â”€ 7-scenes-chess/
    â”‚   â”œâ”€â”€ ...
    â”‚   â”œâ”€â”€ 3DMatch_train_overlap.pkl
    â”‚   â”œâ”€â”€ train_3dmatch.txt
    â”‚   â””â”€â”€ val_3dmatch.txt
    â””â”€â”€ test/
        â”œâ”€â”€ 3DLoMatch/
        â””â”€â”€ 3DMatch/
```

### (2) 3DLoMatch

3DLoMatch shares the same data structure as 3DMatch.

### (3) ScanNet++ iPhone

After running the preprocessing script, the structure should be as follows:

```
datasets/
â””â”€â”€ Scannetpp_iphone/
    â””â”€â”€ test/
        â”œâ”€â”€ 0a5c013435/
        â”‚   â””â”€â”€ iphone/
        â”‚       â”œâ”€â”€ tsdf/
        â”‚       â”‚   â”œâ”€â”€ cloud_bin_0.ply
        â”‚       â”‚   â””â”€â”€ ...
        â”‚       â””â”€â”€ gt.log
        â””â”€â”€ ...
```

### (4) ScanNet++ Faro

After running the preprocessing script, the structure should be as follows:

```
datasets/
â””â”€â”€ scannetpp/
    â””â”€â”€ scannet-plusplus/
        â”œâ”€â”€ 0a5c013435/
        â”‚   â””â”€â”€ scans/
        â”‚       â”œâ”€â”€ gt.log
        â”‚       â”œâ”€â”€ trans_faro_1800x900_scanner_0.ply
        â”‚       â””â”€â”€ ...
        â””â”€â”€ ...
```

### (5) TIERS

The original dataset is available at the official [TIERS GitHub repository](https://github.com/TIERS/tiers-lidars-dataset). In our experiments, we only use the indoor sequences from the TIERS dataset.
The structure should be as follows:

```
datasets/
â””â”€â”€ TIERS/
    â”œâ”€â”€ tiers_indoor06/
    â”‚   â”œâ”€â”€ os0_128/
    â”‚   â”‚   â”œâ”€â”€ scans/
    â”‚   â”‚   â”‚   â”œâ”€â”€ 000000.pcd
    â”‚   â”‚   â”‚   â””â”€â”€ ...
    â”‚   â”‚   â””â”€â”€ poses_kitti.txt
    â”‚   â”œâ”€â”€ os1_64/
    â”‚   â””â”€â”€ vel16/
    â”œâ”€â”€ tiers_indoor08/
    â”œâ”€â”€ tiers_indoor09/
    â”œâ”€â”€ tiers_indoor10/
    â””â”€â”€ tiers_indoor11/
```

## Outdoor Datasets

### (6) KITTI

The structure should be as follows:

```
datasets/
â””â”€â”€ kitti/
    â””â”€â”€ dataset/
        â”œâ”€â”€ pose/
        â”‚   â”œâ”€â”€ 00.txt
        â”‚   â””â”€â”€ ...
        â””â”€â”€ sequences/
            â”œâ”€â”€ 00/
            â””â”€â”€ ...
```

### (7) Waymo Open Dataset

Following [EYOC](https://github.com/liuQuan98/EYOC), we provide the processed WOD dataset.
The structure should be as follows:

```
datasets/
â””â”€â”€ WOD/
    â””â”€â”€ test/
        â””â”€â”€ sequences/
            â”œâ”€â”€ 2601205676330128831_4880_000_4900_000/
            â”‚   â”œâ”€â”€ scans/
            â”‚   â”‚   â”œâ”€â”€ 000000.bin
            â”‚   â”‚   â””â”€â”€ ...
            â”‚   â””â”€â”€ poses.txt
            â””â”€â”€ ...
```

### (8) KAIST

This dataset is derived from the **HeliPR dataset**, using only the **KAIST sequence** for our experiments. The original HeliPR dataset can be downloaded from the [official website](https://sites.google.com/view/heliprdataset).
The structure should be as follows:

```
datasets/
â””â”€â”€ helipr_kaist05/
    â”œâ”€â”€ Aeva/
    â”‚   â”œâ”€â”€ velodyne/
    â”‚   â”‚   â”œâ”€â”€ 000000.bin
    â”‚   â”‚   â””â”€â”€ ...
    â”‚   â”œâ”€â”€ calib.txt
    â”‚   â””â”€â”€ poses.txt
    â”œâ”€â”€ Avia/
    â””â”€â”€ Ouster/
```

### (9) MIT

This dataset is derived from the Kimera-Multi dataset, using only the **MIT sequence** for our experiments. The original dataset can be downloaded from the [official website](https://github.com/MIT-SPARK/Kimera-Multi).
The structure should be as follows:

```
datasets/
â””â”€â”€ kimera-multi/
    â””â”€â”€ acl_jackal/
        â”œâ”€â”€ scans/
        â”‚   â”œâ”€â”€ 000000.pcd
        â”‚   â””â”€â”€ ...
        â”œâ”€â”€ kimera_multi1_map.pcd
        â”œâ”€â”€ poses_kitti.txt
        â””â”€â”€ poses_tum.txt
```

### (10) ETH

The structure should be as follows:

```
datasets/
â””â”€â”€ ETH/
    â”œâ”€â”€ gazebo_summer/
    â”œâ”€â”€ gazebo_winter/
    â”œâ”€â”€ wood_autmn/
    â””â”€â”€ wood_summer/
```

### (11) Oxford

This dataset is based on the [Newer College Dataset](https://ori-drs.github.io/newer-college-dataset/). We use selected sequences from the dataset for evaluation.
The structure should be as follows:

```
datasets/
â””â”€â”€ newer-college/
    â”œâ”€â”€ 01_short_experiments/
    â”‚   â”œâ”€â”€ scans/
    â”‚   â”‚   â”œâ”€â”€ 000000.pcd
    â”‚   â”‚   â””â”€â”€ ...
    â”‚   â”œâ”€â”€ 01_short_experiments_map.pcd
    â”‚   â”œâ”€â”€ poses_kitti.txt
    â”‚   â””â”€â”€ poses_tum.txt
    â”œâ”€â”€ 05_quad_with_dynamics/
    â””â”€â”€ 07_parkland_mound/
```
